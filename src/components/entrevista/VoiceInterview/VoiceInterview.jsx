// src/components/entrevista/VoiceInterview/VoiceInterview.jsx
import { useState, useEffect, useRef, useCallback } from 'react';
import { motion, AnimatePresence } from 'framer-motion';
import { Mic, MicOff, Volume2, VolumeX, Loader, ChevronDown, ChevronUp, Send } from 'lucide-react';
import SpeechRecognition, { useSpeechRecognition } from 'react-speech-recognition';
import { toast } from 'react-toastify';
import { useTheme } from '../../../context/ThemeContext/ThemeContext';
import Background from '../../layout/Background/Background';

const VoiceInterview = ({
  onSendMessage,
  loading,
  lastAIMessage,
  disabled,
  onFinalizarEntrevista,
  onAbandonarEntrevista,
  vozSeleccionada = 'alloy' // Voz de OpenAI TTS por defecto
}) => {
  // Theme
  const { theme } = useTheme();
  const isDark = theme === 'dark';

  // Estados principales
  const [isListening, setIsListening] = useState(false);
  const [isSpeaking, setIsSpeaking] = useState(false);
  const [voiceEnabled, setVoiceEnabled] = useState(true);
  const [audioSupported, setAudioSupported] = useState(true);

  // Estados de voz
  const [availableVoices, setAvailableVoices] = useState([]);
  const [selectedVoice, setSelectedVoice] = useState(null);
  const [showVoiceSelector, setShowVoiceSelector] = useState(false);
  const [showInitialVoiceSelection, setShowInitialVoiceSelection] = useState(true);
  const [presetVoices, setPresetVoices] = useState([]);

  // Estados de detecci√≥n de audio
  const [isDetectingVoice, setIsDetectingVoice] = useState(false);
  const [audioLevel, setAudioLevel] = useState(0);

  // Referencias
  const synthRef = useRef(window.speechSynthesis);
  const utteranceRef = useRef(null);
  const lastMessageRef = useRef(null);
  const audioContextRef = useRef(null);
  const analyserRef = useRef(null);
  const micStreamRef = useRef(null);
  const animationFrameRef = useRef(null);
  const lastSpeechTimeRef = useRef(Date.now());
  const silenceTimerRef = useRef(null);

  // Hook de reconocimiento de voz
  const {
    transcript,
    listening,
    resetTranscript,
    browserSupportsSpeechRecognition
  } = useSpeechRecognition();

  // Log de la voz seleccionada
  useEffect(() => {
    console.log('üîä Voz de OpenAI TTS seleccionada:', vozSeleccionada);
  }, [vozSeleccionada]);

  // Log del transcript cada vez que cambia
  useEffect(() => {
    console.log('üìù Transcript actualizado:', transcript);
    console.log('üìù Longitud:', transcript.length);
  }, [transcript]);

  // Verificar soporte del navegador
  useEffect(() => {
    if (!browserSupportsSpeechRecognition) {
      setAudioSupported(false);
      toast.error('Tu navegador no soporta reconocimiento de voz. Usa Chrome o Edge.');
    }

    if (!window.speechSynthesis) {
      setAudioSupported(false);
      toast.error('Tu navegador no soporta s√≠ntesis de voz.');
    }

    // Cargar voces disponibles
    const loadVoices = () => {
      const voices = synthRef.current.getVoices();

      console.log('üîä Todas las voces disponibles:', voices.map(v => ({ name: v.name, lang: v.lang })));

      // PASO 1: Filtrar voces de espa√±ol LATINO (evitar Espa√±a)
      const latinSpanishVoices = voices.filter(voice => {
        const nameLower = voice.name.toLowerCase();
        const langLower = voice.lang.toLowerCase();
        const isLatinAmerican = (
          langLower.includes('es-mx') || langLower.includes('es-pe') || langLower.includes('es-co') ||
          langLower.includes('es-ar') || langLower.includes('es-cl') || langLower.includes('es-ve') ||
          nameLower.includes('raul') || nameLower.includes('sabina') || nameLower.includes('jorge') || nameLower.includes('camila')
        );
        const isSpain = langLower.includes('es-es') || nameLower.includes('elena') || nameLower.includes('pablo') || nameLower.includes('alvaro');
        return isLatinAmerican && !isSpain;
      });

      // PASO 2: Filtrar solo voces NATURALES/NEURALES (no rob√≥ticas)
      const naturalVoices = latinSpanishVoices.filter(voice => {
        const nameLower = voice.name.toLowerCase();
        return nameLower.includes('neural') || nameLower.includes('natural') || nameLower.includes('online') ||
          nameLower.includes('raul') || nameLower.includes('sabina') || nameLower.includes('jorge') || nameLower.includes('camila');
      });

      console.log('üéôÔ∏è Voces naturales latinas:', naturalVoices.map(v => v.name));

      // Usar voces naturales o latinas como fallback
      let selectedVoices = naturalVoices.length > 0 ? naturalVoices : latinSpanishVoices;

      // Si no hay latinas, buscar cualquier espa√±ol natural (sin Espa√±a)
      if (selectedVoices.length === 0) {
        selectedVoices = voices.filter(v => {
          const n = v.name.toLowerCase(), l = v.lang.toLowerCase();
          return (l.includes('es') && !l.includes('es-es') && (n.includes('neural') || n.includes('natural')));
        });
      }

      // √öltimo recurso: cualquier espa√±ol
      if (selectedVoices.length === 0) {
        selectedVoices = voices.filter(v => v.lang.toLowerCase().includes('es')).slice(0, 4);
      }

      // Limitar a m√°ximo 4 voces
      const finalVoices = selectedVoices.slice(0, 4);

      // Formatear las voces seleccionadas
      const foundPresets = finalVoices.map((voice, index) => {
        // Determinar si es femenina o masculina bas√°ndose en el nombre
        const nameLower = voice.name.toLowerCase();
        let gender = 'Neutral';

        if (nameLower.includes('female') || nameLower.includes('mujer') ||
          nameLower.includes('helena') || nameLower.includes('monica') ||
          nameLower.includes('sabina') || nameLower.includes('paulina')) {
          gender = 'Femenina';
        } else if (nameLower.includes('male') || nameLower.includes('hombre') ||
          nameLower.includes('pablo') || nameLower.includes('jorge') ||
          nameLower.includes('raul') || nameLower.includes('diego')) {
          gender = 'Masculina';
        }

        return {
          voice: voice,
          label: `Voz ${index + 1} (${gender})`
        };
      });

      setPresetVoices(foundPresets);
      console.log('üîä Voces predefinidas cargadas:', foundPresets.map(p => ({
        label: p.label,
        name: p.voice.name,
        lang: p.voice.lang
      })));
    };

    loadVoices();

    // Recargar voces cuando est√©n disponibles
    if (synthRef.current.onvoiceschanged !== undefined) {
      synthRef.current.onvoiceschanged = loadVoices;
    }
  }, [browserSupportsSpeechRecognition]);

  // Sincronizar estado de escucha
  useEffect(() => {
    setIsListening(listening);
    console.log('üé§ Estado de escucha:', listening ? 'ACTIVO' : 'INACTIVO');
  }, [listening]);

  // Funci√≥n para sintetizar voz (se define antes del useEffect)
  const speakText = useCallback((text) => {
    if (!window.speechSynthesis || !voiceEnabled) {
      console.warn('‚ö†Ô∏è speechSynthesis no disponible o voz deshabilitada');
      return;
    }

    // Si no hay voz seleccionada, intentar obtener una voz por defecto
    let voiceToUse = selectedVoice;
    if (!voiceToUse) {
      const voices = synthRef.current.getVoices();
      const spanishVoices = voices.filter(v => v.lang.includes('es') || v.lang.includes('ES'));
      voiceToUse = spanishVoices[0] || voices[0];
      console.warn('‚ö†Ô∏è No hab√≠a voz seleccionada, usando voz por defecto:', voiceToUse?.name);

      if (!voiceToUse) {
        console.error('‚ùå No hay voces disponibles en el sistema');
        return;
      }

      // Actualizar selectedVoice para futuros usos
      setSelectedVoice(voiceToUse);
    }

    // Cancelar cualquier voz anterior
    synthRef.current.cancel();

    // Crear nueva utterance
    utteranceRef.current = new SpeechSynthesisUtterance(text);
    utteranceRef.current.voice = voiceToUse;
    utteranceRef.current.lang = 'es-ES';
    utteranceRef.current.rate = 0.95;
    utteranceRef.current.pitch = 1.1;
    utteranceRef.current.volume = 1.0;

    // Eventos
    utteranceRef.current.onstart = () => {
      setIsSpeaking(true);
      console.log('üîä Reproduciendo con voz:', voiceToUse.name);
    };

    utteranceRef.current.onend = () => {
      setIsSpeaking(false);
      console.log('üîá Reproducci√≥n finalizada');
    };

    utteranceRef.current.onerror = (event) => {
      console.error('‚ùå Error en s√≠ntesis de voz:', event);
      setIsSpeaking(false);
      toast.error('Error al reproducir la voz de la IA');
    };

    // Reproducir
    console.log('üéôÔ∏è Iniciando s√≠ntesis de voz...');
    synthRef.current.speak(utteranceRef.current);
  }, [voiceEnabled, selectedVoice]);

  // Reproducir respuesta de IA cuando llega un nuevo mensaje
  useEffect(() => {
    if (lastAIMessage && voiceEnabled && !loading && lastAIMessage !== lastMessageRef.current) {
      lastMessageRef.current = lastAIMessage;
      console.log('üîä Intentando reproducir voz de IA...');
      speakText(lastAIMessage);

      // Detectar si la IA ha finalizado la entrevista
      const frasesFin = [
        'entrevista ha concluido',
        'hemos terminado',
        'finalizado la entrevista',
        'muchas gracias por tu tiempo',
        'fin de la entrevista',
        'entrevista finalizada',
        'eso es todo por hoy',
        'ha sido un placer',
        'termina aqu√≠'
      ];

      const entrevistaFinalizadaPorIA = frasesFin.some(frase =>
        lastAIMessage.toLowerCase().includes(frase)
      );

      if (entrevistaFinalizadaPorIA && onFinalizarEntrevista) {
        console.log('üèÅ IA ha finalizado la entrevista autom√°ticamente en modo voz');
        toast.success('La entrevista ha finalizado. Generando resultados...');

        // Ejecutar finalizaci√≥n despu√©s de que termine de hablar
        setTimeout(() => {
          onFinalizarEntrevista();
        }, 2000);
      }
    } else if (lastAIMessage && voiceEnabled && !loading && !selectedVoice) {
      console.warn('‚ö†Ô∏è No hay voz seleccionada todav√≠a, esperando...');
    }
  }, [lastAIMessage, voiceEnabled, loading, selectedVoice, speakText, onFinalizarEntrevista]);

  // Inicializar detector de audio
  const initAudioDetection = useCallback(async () => {
    try {
      console.log('üé§ Iniciando detecci√≥n de audio...');
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        }
      });
      micStreamRef.current = stream;

      // @ts-ignore
      audioContextRef.current = new (window.AudioContext || window.webkitAudioContext)();
      analyserRef.current = audioContextRef.current.createAnalyser();
      analyserRef.current.fftSize = 256;
      analyserRef.current.smoothingTimeConstant = 0.8;

      const source = audioContextRef.current.createMediaStreamSource(stream);
      source.connect(analyserRef.current);

      const bufferLength = analyserRef.current.frequencyBinCount;
      const dataArray = new Uint8Array(bufferLength);

      const detectSound = () => {
        if (!analyserRef.current) return;

        analyserRef.current.getByteFrequencyData(dataArray);

        // Calcular nivel de audio promedio
        const average = dataArray.reduce((sum, value) => sum + value, 0) / bufferLength;
        setAudioLevel(average);

        // Detectar si hay voz (umbral: 25)
        const hasVoice = average > 25;

        setIsDetectingVoice(hasVoice);

        if (hasVoice) {
          // Hay voz detectada - reiniciar timer de silencio
          lastSpeechTimeRef.current = Date.now();

          // Cancelar timer anterior si existe
          if (silenceTimerRef.current) {
            clearTimeout(silenceTimerRef.current);
            silenceTimerRef.current = null;
          }
        } else {
          // No hay voz - verificar si han pasado 3.5 segundos de silencio
          const silenceDuration = Date.now() - lastSpeechTimeRef.current;

          if (silenceDuration >= 3500 && !silenceTimerRef.current) {
            // Iniciar timer para auto-enviar
            silenceTimerRef.current = setTimeout(() => {
              console.log('‚è±Ô∏è Auto-enviando por 3.5 segundos de silencio');
              if (transcript.trim()) {
                stopListeningAndSend();
              }
              silenceTimerRef.current = null;
            }, 100); // Small delay to ensure state is updated
          }
        }

        animationFrameRef.current = requestAnimationFrame(detectSound);
      };

      detectSound();
      console.log('‚úÖ Detecci√≥n de audio iniciada');
    } catch (error) {
      console.error('‚ùå Error al inicializar detecci√≥n de audio:', error);
      toast.error('No se pudo acceder al micr√≥fono. Verifica los permisos.');
    }
  }, []);

  // Detener detector de audio
  const stopAudioDetection = useCallback(() => {
    console.log('üõë Deteniendo detecci√≥n de audio...');

    if (animationFrameRef.current) {
      cancelAnimationFrame(animationFrameRef.current);
      animationFrameRef.current = null;
    }

    if (silenceTimerRef.current) {
      clearTimeout(silenceTimerRef.current);
      silenceTimerRef.current = null;
    }

    if (audioContextRef.current && audioContextRef.current.state !== 'closed') {
      audioContextRef.current.close();
      audioContextRef.current = null;
    }

    if (micStreamRef.current) {
      micStreamRef.current.getTracks().forEach(track => track.stop());
      micStreamRef.current = null;
    }

    analyserRef.current = null;
    setIsDetectingVoice(false);
    setAudioLevel(0);
  }, []);

  // Limpiar al desmontar
  useEffect(() => {
    return () => {
      stopAudioDetection();
      if (synthRef.current) {
        synthRef.current.cancel();
      }
    };
  }, [stopAudioDetection]);

  // Iniciar/detener detecci√≥n cuando cambia isListening
  useEffect(() => {
    if (isListening) {
      initAudioDetection();
    } else {
      stopAudioDetection();
    }
  }, [isListening, initAudioDetection, stopAudioDetection]);

  // Funci√≥n para iniciar grabaci√≥n
  const startListening = () => {
    if (!audioSupported) {
      toast.error('Reconocimiento de voz no disponible');
      return;
    }

    console.log('üé§ Iniciando escucha...');
    resetTranscript();
    lastSpeechTimeRef.current = Date.now();

    SpeechRecognition.startListening({
      continuous: true,
      language: 'es-ES'
    });

    toast.info('üé§ Escuchando... Habla ahora');
  };

  // Funci√≥n para detener grabaci√≥n y enviar
  const stopListeningAndSend = () => {
    console.log('‚èπÔ∏è Deteniendo escucha...');
    console.log('üìù Transcript actual:', transcript);
    console.log('üìù Longitud del transcript:', transcript.trim().length);

    SpeechRecognition.stopListening();
    stopAudioDetection();

    if (transcript.trim()) {
      console.log('üì§ Enviando transcripci√≥n:', transcript);
      onSendMessage(transcript);
      toast.success('Mensaje enviado');
      resetTranscript();
    } else {
      console.warn('‚ö†Ô∏è No hay texto para enviar');
      toast.warn('No se detect√≥ ninguna voz');
    }
  };

  // Funci√≥n para alternar grabaci√≥n
  const toggleListening = () => {
    if (isListening) {
      stopListeningAndSend();
    } else {
      startListening();
    }
  };

  // Funci√≥n para enviar manualmente (para testing)
  const handleManualSend = () => {
    console.log('üì§ Env√≠o manual activado');
    console.log('üìù Transcript:', transcript);

    if (transcript.trim()) {
      SpeechRecognition.stopListening();
      stopAudioDetection();
      onSendMessage(transcript);
      toast.success('Mensaje enviado manualmente');
      resetTranscript();
    } else {
      toast.warn('No hay texto para enviar');
    }
  };

  // Funci√≥n para detener la voz
  const stopSpeaking = () => {
    if (synthRef.current) {
      synthRef.current.cancel();
      setIsSpeaking(false);
    }
  };

  // Funci√≥n para alternar s√≠ntesis de voz
  const toggleVoiceOutput = () => {
    const newState = !voiceEnabled;
    setVoiceEnabled(newState);

    if (!newState) {
      stopSpeaking();
      toast.info('Respuestas de voz desactivadas');
    } else {
      toast.success('Respuestas de voz activadas');
    }
  };

  if (!audioSupported) {
    return (
      <div style={{
        padding: '2rem',
        textAlign: 'center',
        background: '#fef2f2',
        borderRadius: '16px',
        border: '2px solid #fecaca'
      }}>
        <p style={{ color: '#dc2626', margin: 0, fontSize: '1rem', fontWeight: 500 }}>
          Tu navegador no soporta entrevistas por voz. Por favor, usa Google Chrome o Microsoft Edge.
        </p>
      </div>
    );
  }

  // Colores din√°micos basados en el tema
  const colors = {
    bgSecondary: isDark ? 'rgba(30, 41, 59, 0.95)' : 'rgba(255, 255, 255, 0.95)',
    bgTertiary: isDark ? 'rgba(51, 65, 85, 0.8)' : 'rgba(243, 244, 246, 0.8)',
    headerBg: isDark ? 'rgba(15, 23, 42, 0.95)' : 'rgba(31, 41, 55, 0.95)',
    textPrimary: isDark ? '#f1f5f9' : '#1f2937',
    textSecondary: isDark ? '#cbd5e1' : '#6b7280',
    border: isDark ? '#475569' : '#e5e7eb',
    accent: '#667eea',
    accentHover: '#764ba2',
    error: '#ef4444'
  };

  return (
    <>
      <Background />

      {/* MODAL DE SELECCI√ìN INICIAL DE VOZ */}
      {showInitialVoiceSelection && presetVoices.length > 0 && (
        <div style={{
          position: 'fixed',
          top: 0,
          left: 0,
          right: 0,
          bottom: 0,
          background: 'rgba(0, 0, 0, 0.85)',
          display: 'flex',
          alignItems: 'center',
          justifyContent: 'center',
          zIndex: 1000,
          padding: '1rem'
        }}>
          <motion.div
            initial={{ opacity: 0, scale: 0.9 }}
            animate={{ opacity: 1, scale: 1 }}
            style={{
              background: colors.bgSecondary,
              borderRadius: '20px',
              padding: 'clamp(1.5rem, 4vw, 3rem)',
              maxWidth: '600px',
              width: '100%',
              border: `2px solid ${colors.border}`,
              boxShadow: '0 25px 50px -12px rgba(0, 0, 0, 0.5)'
            }}
          >
            <h2 style={{
              margin: '0 0 1rem 0',
              color: colors.textPrimary,
              fontSize: 'clamp(1.25rem, 3vw, 1.75rem)',
              fontWeight: 700,
              textAlign: 'center'
            }}>
              Selecciona una Voz para la Entrevista
            </h2>
            <p style={{
              margin: '0 0 2rem 0',
              color: colors.textSecondary,
              fontSize: 'clamp(0.875rem, 2vw, 1rem)',
              textAlign: 'center'
            }}>
              Elige la voz que prefieras para las respuestas de la IA
            </p>

            <div style={{
              display: 'grid',
              gap: '1rem',
              gridTemplateColumns: 'repeat(auto-fit, minmax(150px, 1fr))'
            }}>
              {presetVoices.map((preset, index) => (
                <motion.button
                  key={index}
                  whileHover={{ scale: 1.05 }}
                  whileTap={{ scale: 0.95 }}
                  onClick={() => {
                    setSelectedVoice(preset.voice);
                    setShowInitialVoiceSelection(false);
                    toast.success(`Voz seleccionada: ${preset.label}`);
                    console.log('üîä Voz elegida:', preset.voice.name);
                  }}
                  style={{
                    padding: 'clamp(1rem, 3vw, 1.5rem)',
                    background: `linear-gradient(135deg, ${colors.accent} 0%, ${colors.accentHover} 100%)`,
                    color: 'white',
                    border: 'none',
                    borderRadius: '12px',
                    fontSize: 'clamp(0.875rem, 2vw, 1rem)',
                    fontWeight: 600,
                    cursor: 'pointer',
                    transition: 'all 0.3s ease',
                    textAlign: 'center'
                  }}
                >
                  <Volume2 size={28} style={{ marginBottom: '0.5rem' }} />
                  <div>{preset.label}</div>
                  <div style={{
                    fontSize: 'clamp(0.7rem, 1.5vw, 0.8rem)',
                    opacity: 0.8,
                    marginTop: '0.25rem'
                  }}>
                    {preset.voice.name.substring(0, 30)}
                  </div>
                </motion.button>
              ))}
            </div>
          </motion.div>
        </div>
      )}

      <div style={{
        display: 'flex',
        flexDirection: 'column',
        minHeight: '100vh',
        padding: 'clamp(0.75rem, 2vw, 1.5rem)',
        gap: 'clamp(0.75rem, 2vw, 1.5rem)',
        position: 'relative',
        zIndex: 1
      }}>
        {/* HEADER */}
        <div style={{
          background: colors.headerBg,
          backdropFilter: 'blur(10px)',
          borderRadius: 'clamp(8px, 2vw, 12px)',
          padding: 'clamp(0.75rem, 2vw, 1rem) clamp(1rem, 3vw, 1.5rem)',
          display: 'flex',
          alignItems: 'center',
          justifyContent: 'space-between',
          border: `1px solid ${colors.border}`,
          flexWrap: 'wrap',
          gap: '0.75rem'
        }}>
          <h2 style={{
            margin: 0,
            color: colors.textPrimary,
            fontSize: 'clamp(1rem, 2.5vw, 1.25rem)',
            fontWeight: 700
          }}>
            ENTREVISTA POR VOZ
          </h2>

          {/* Botones de Finalizar y Abandonar */}
          <div style={{
            display: 'flex',
            gap: '0.75rem',
            alignItems: 'center'
          }}>
            <button
              onClick={onFinalizarEntrevista}
              disabled={disabled || loading}
              style={{
                padding: 'clamp(0.5rem, 1.5vw, 0.75rem) clamp(1rem, 2.5vw, 1.5rem)',
                background: 'white',
                color: '#6b7280',
                border: '2px solid #e5e7eb',
                borderRadius: '8px',
                fontSize: 'clamp(0.75rem, 1.8vw, 0.875rem)',
                fontWeight: 600,
                cursor: disabled || loading ? 'not-allowed' : 'pointer',
                transition: 'all 0.3s ease',
                whiteSpace: 'nowrap',
                opacity: disabled || loading ? 0.5 : 1
              }}
            >
              Finalizar
            </button>
            <button
              onClick={onAbandonarEntrevista}
              disabled={disabled || loading}
              style={{
                padding: 'clamp(0.5rem, 1.5vw, 0.75rem) clamp(1rem, 2.5vw, 1.5rem)',
                background: colors.error,
                color: 'white',
                border: `2px solid ${colors.error}`,
                borderRadius: '8px',
                fontSize: 'clamp(0.75rem, 1.8vw, 0.875rem)',
                fontWeight: 600,
                cursor: disabled || loading ? 'not-allowed' : 'pointer',
                transition: 'all 0.3s ease',
                whiteSpace: 'nowrap',
                opacity: disabled || loading ? 0.5 : 1
              }}
            >
              Abandonar
            </button>
          </div>
        </div>

        {/* LAYOUT PRINCIPAL */}
        <div style={{
          display: 'flex',
          flexDirection: 'column',
          gap: 'clamp(1rem, 2vw, 1.5rem)',
          flex: 1
        }}>
          {/* SECCI√ìN: TEXTO DE ENTREVISTA */}
          <div style={{
            background: colors.bgSecondary,
            backdropFilter: 'blur(10px)',
            borderRadius: 'clamp(8px, 2vw, 12px)',
            padding: 'clamp(1rem, 3vw, 2rem)',
            flex: '0 0 auto',
            minHeight: 'clamp(200px, 30vh, 280px)',
            display: 'flex',
            flexDirection: 'column',
            border: `1px solid ${colors.border}`
          }}>
            <div style={{
              marginBottom: '1.5rem',
              display: 'flex',
              justifyContent: 'space-between',
              alignItems: 'center'
            }}>
              <h3 style={{
                margin: 0,
                fontSize: 'clamp(0.875rem, 2vw, 1rem)',
                fontWeight: 700,
                color: colors.textPrimary,
                letterSpacing: '1px',
                textTransform: 'uppercase'
              }}>
                TEXTO DE ENTREVISTA
              </h3>

              {/* Bot√≥n de env√≠o manual */}
              {transcript && isListening && (
                <motion.button
                  onClick={handleManualSend}
                  whileHover={{ scale: 1.05 }}
                  whileTap={{ scale: 0.95 }}
                  style={{
                    padding: '0.5rem 1rem',
                    background: '#667eea',
                    color: 'white',
                    border: 'none',
                    borderRadius: '8px',
                    fontSize: '0.875rem',
                    fontWeight: 600,
                    cursor: 'pointer',
                    display: 'flex',
                    alignItems: 'center',
                    gap: '0.5rem'
                  }}
                >
                  <Send size={16} />
                  Enviar
                </motion.button>
              )}
            </div>

            <div style={{
              flex: 1,
              display: 'flex',
              alignItems: 'center',
              justifyContent: 'center',
              background: colors.bgTertiary,
              borderRadius: '8px',
              padding: '1.5rem',
              border: `1px solid ${colors.border}`
            }}>
              {transcript ? (
                <motion.div
                  initial={{ opacity: 0 }}
                  animate={{ opacity: 1 }}
                  style={{ width: '100%' }}
                >
                  <p style={{
                    color: colors.textPrimary,
                    margin: 0,
                    fontSize: '1.1rem',
                    lineHeight: '1.8',
                    fontWeight: 400
                  }}>
                    "{transcript}"
                  </p>
                  <div style={{
                    marginTop: '1rem',
                    fontSize: '0.75rem',
                    color: colors.textSecondary
                  }}>
                    Caracteres: {transcript.length} | Audio: {audioLevel.toFixed(0)}
                  </div>
                </motion.div>
              ) : (
                <p style={{
                  color: '#6b7280',
                  fontSize: '1rem',
                  fontStyle: 'italic',
                  margin: 0
                }}>
                  {isListening ? 'Esperando tu respuesta...' : 'Presiona el micr√≥fono para comenzar'}
                </p>
              )}
            </div>
          </div>

          {/* SECCI√ìN: OPCIONES DE ANIMACION DE VOZ Y ENVIAR AUDIO DE TEXTO */}
          <div style={{
            background: 'linear-gradient(135deg, #667eea 0%, #764ba2 100%)',
            borderRadius: '12px',
            padding: '2.5rem',
            flex: 1,
            display: 'flex',
            flexDirection: 'column',
            alignItems: 'center',
            justifyContent: 'center',
            gap: '2rem',
            boxShadow: '0 10px 25px rgba(102, 126, 234, 0.3)'
          }}>
            {/* Visualizaci√≥n seg√∫n estado */}
            {loading ? (
              <div style={{ textAlign: 'center', color: 'white' }}>
                <Loader size={56} className="animate-spin" style={{ margin: '0 auto' }} />
                <p style={{ marginTop: '1.5rem', fontSize: '1.2rem', fontWeight: 600 }}>
                  Procesando respuesta...
                </p>
              </div>
            ) : isSpeaking ? (
              <div style={{ textAlign: 'center', color: 'white' }}>
                <div style={{
                  display: 'flex',
                  alignItems: 'center',
                  justifyContent: 'center',
                  gap: '8px',
                  height: '100px',
                  marginBottom: '1.5rem'
                }}>
                  {[...Array(7)].map((_, i) => (
                    <motion.div
                      key={i}
                      animate={{
                        scaleY: [1, 2.5, 0.8, 2, 1.2, 1],
                        opacity: [0.6, 1, 0.7, 1, 0.8, 0.6]
                      }}
                      transition={{
                        duration: 1.2,
                        repeat: Infinity,
                        delay: i * 0.1,
                        ease: "easeInOut"
                      }}
                      style={{
                        width: '10px',
                        height: '50px',
                        background: 'white',
                        borderRadius: '5px',
                        transformOrigin: 'center'
                      }}
                    />
                  ))}
                </div>
                <p style={{ fontSize: '1.3rem', fontWeight: 600 }}>
                  La IA est√° hablando...
                </p>
                <p style={{ fontSize: '0.9rem', opacity: 0.9, marginTop: '0.5rem' }}>
                  Escucha la respuesta
                </p>
              </div>
            ) : isListening ? (
              <div style={{ textAlign: 'center', color: 'white' }}>
                <div style={{
                  position: 'relative',
                  width: '150px',
                  height: '150px',
                  margin: '0 auto 1.5rem',
                  display: 'flex',
                  alignItems: 'center',
                  justifyContent: 'center'
                }}>
                  {isDetectingVoice && (
                    <>
                      <motion.div
                        animate={{
                          scale: [1, 2.2],
                          opacity: [0.7, 0]
                        }}
                        transition={{
                          duration: 1.5,
                          repeat: Infinity,
                          ease: "easeOut"
                        }}
                        style={{
                          position: 'absolute',
                          width: '150px',
                          height: '150px',
                          border: '4px solid white',
                          borderRadius: '50%'
                        }}
                      />
                      <motion.div
                        animate={{
                          scale: [1, 2.2],
                          opacity: [0.7, 0]
                        }}
                        transition={{
                          duration: 1.5,
                          repeat: Infinity,
                          delay: 0.5,
                          ease: "easeOut"
                        }}
                        style={{
                          position: 'absolute',
                          width: '150px',
                          height: '150px',
                          border: '4px solid white',
                          borderRadius: '50%'
                        }}
                      />
                    </>
                  )}

                  <motion.div
                    animate={isDetectingVoice ? {
                      scale: [1, 1.1, 1],
                    } : {}}
                    transition={{
                      duration: 0.8,
                      repeat: Infinity,
                    }}
                    style={{
                      width: '120px',
                      height: '120px',
                      background: isDetectingVoice
                        ? 'rgba(239, 68, 68, 0.4)'
                        : 'rgba(255, 255, 255, 0.2)',
                      borderRadius: '50%',
                      display: 'flex',
                      alignItems: 'center',
                      justifyContent: 'center',
                      border: `4px solid ${isDetectingVoice ? '#ef4444' : 'white'}`,
                      transition: 'all 0.3s ease',
                      position: 'relative',
                      zIndex: 1
                    }}
                  >
                    <Mic size={48} color="white" />
                  </motion.div>
                </div>

                <p style={{ fontSize: '1.3rem', fontWeight: 600, margin: 0 }}>
                  {isDetectingVoice ? '¬°Te estoy escuchando!' : 'Esperando tu voz...'}
                </p>
                <p style={{ fontSize: '0.9rem', opacity: 0.9, marginTop: '0.5rem' }}>
                  {isDetectingVoice ? 'Habla con claridad' : 'Empieza a hablar cuando est√©s listo'}
                </p>
              </div>
            ) : (
              <div style={{ textAlign: 'center', color: 'white' }}>
                <MicOff size={72} style={{ opacity: 0.7, marginBottom: '1.5rem' }} />
                <p style={{ fontSize: '1.3rem', fontWeight: 600, margin: 0 }}>
                  Presiona el micr√≥fono para empezar
                </p>
                <p style={{ fontSize: '0.9rem', opacity: 0.9, marginTop: '0.5rem' }}>
                  Habla y luego presiona "Enviar" o el bot√≥n rojo nuevamente
                </p>
              </div>
            )}

            {/* Controles */}
            <div style={{
              display: 'flex',
              gap: '1.5rem',
              alignItems: 'center',
              marginTop: '1rem'
            }}>
              <motion.button
                onClick={toggleListening}
                disabled={disabled || loading || isSpeaking}
                whileHover={!disabled && !loading && !isSpeaking ? { scale: 1.05 } : {}}
                whileTap={!disabled && !loading && !isSpeaking ? { scale: 0.95 } : {}}
                style={{
                  width: '100px',
                  height: '100px',
                  borderRadius: '50%',
                  border: 'none',
                  background: isListening
                    ? 'linear-gradient(135deg, #ef4444 0%, #dc2626 100%)'
                    : 'white',
                  color: isListening ? 'white' : '#667eea',
                  cursor: (disabled || loading || isSpeaking) ? 'not-allowed' : 'pointer',
                  opacity: (disabled || loading || isSpeaking) ? 0.5 : 1,
                  display: 'flex',
                  alignItems: 'center',
                  justifyContent: 'center',
                  boxShadow: isListening
                    ? '0 0 0 0 rgba(239, 68, 68, 0.7)'
                    : '0 8px 16px rgba(0,0,0,0.2)',
                  animation: isListening ? 'pulse 2s infinite' : 'none',
                  transition: 'all 0.3s ease'
                }}
              >
                {isListening ? <Mic size={48} /> : <MicOff size={48} />}
              </motion.button>

              <motion.button
                onClick={toggleVoiceOutput}
                disabled={disabled}
                whileHover={!disabled ? { scale: 1.05 } : {}}
                whileTap={!disabled ? { scale: 0.95 } : {}}
                style={{
                  width: '70px',
                  height: '70px',
                  borderRadius: '50%',
                  border: 'none',
                  background: voiceEnabled
                    ? 'rgba(255, 255, 255, 0.3)'
                    : 'rgba(255, 255, 255, 0.15)',
                  color: 'white',
                  cursor: disabled ? 'not-allowed' : 'pointer',
                  opacity: disabled ? 0.5 : 1,
                  display: 'flex',
                  alignItems: 'center',
                  justifyContent: 'center',
                  backdropFilter: 'blur(10px)',
                  transition: 'all 0.3s ease',
                  boxShadow: '0 4px 12px rgba(0,0,0,0.15)'
                }}
              >
                {voiceEnabled ? <Volume2 size={32} /> : <VolumeX size={32} />}
              </motion.button>
            </div>
          </div>
        </div>

        {/* Estilos para animaciones */}
        <style>{`
        @keyframes pulse {
          0% {
            box-shadow: 0 0 0 0 rgba(239, 68, 68, 0.7);
          }
          70% {
            box-shadow: 0 0 0 25px rgba(239, 68, 68, 0);
          }
          100% {
            box-shadow: 0 0 0 0 rgba(239, 68, 68, 0);
          }
        }

        .animate-spin {
          animation: spin 1s linear infinite;
        }

        @keyframes spin {
          from {
            transform: rotate(0deg);
          }
          to {
            transform: rotate(360deg);
          }
        }
      `}</style>
      </div>
    </>
  );
};

export default VoiceInterview;
